{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a3b4d8f62822>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# code here copied from the Udacity course material\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from functools import partial\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import asyncio\n",
    "\n",
    "from utils import *\n",
    "from features import *\n",
    "from boxes import *\n",
    "from images import *\n",
    "from detection import *\n",
    "from search import *\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import ImageSequenceClip, VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timages, tfiles = load_test_images()\n",
    "arr2img(cv2.cvtColor(timages[0], cv2.COLOR_BGR2RGB))\n",
    "#arr2img(images[0][1])\n",
    "#plt.imshow(images[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vimages, vframes = load_test_video()\n",
    "pimages, pframes = load_test_video(file_name='project_video.mp4')\n",
    "arr2img(cv2.cvtColor(vimages[5], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, files = load_images()\n",
    "arr2img(cv2.cvtColor(images[0],cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_images, not_car_images = load_car_not_car_images()\n",
    "len(car_images),len(not_car_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hog Classify\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_size = 10000\n",
    "# cars = car_images[0:sample_size]\n",
    "# notcars = not_car_images[0:sample_size]\n",
    "\n",
    "cars = car_images\n",
    "notcars = not_car_images\n",
    "\n",
    "colorspace = 'YCrCb' # Can be BGR, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 32\n",
    "pix_per_cell = 16\n",
    "cell_per_block = 2\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "\n",
    "t=time.time()\n",
    "# also appended a color histogram into the features\n",
    "car_features = extract_hog_features(cars, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "notcar_features = extract_hog_features(notcars, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract HOG features...')\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "#X_scaler = StandardScaler(with_mean=True, with_std=True).fit(X)\n",
    "X_scaler = RobustScaler().fit(X)\n",
    "# X_scaler = MinMaxScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using:',hog_channel,'hog channel',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_ind = np.random.randint(0, len(car_images))\n",
    "# Plot an example of raw and scaled features\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(cv2.cvtColor(car_images[car_ind], cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "plt.subplot(132)\n",
    "plt.plot(X[car_ind])\n",
    "plt.title('Raw Features')\n",
    "plt.subplot(133)\n",
    "plt.plot(scaled_X[car_ind])\n",
    "plt.title('Normalized Features')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Train Accuracy of SVC = ', round(svc.score(X_train, y_train), 4))\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = WindowBoxes(height=car_images[0].shape[0], width=car_images[0].shape[1])\n",
    "total=0\n",
    "for size, windows in wb.window_boxes_dict.items():\n",
    "    count=len(windows)\n",
    "    total = total + count\n",
    "    print(\"{} count {}\".format(size, count))\n",
    "\n",
    "print(\"total\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boxes import WindowBoxes\n",
    "images, _ = load_test_images()\n",
    "\n",
    "@interact\n",
    "def window_test(images=fixed(pimages), i:(0,len(pimages)-1)=0, \n",
    "                all_shapes=True,\n",
    "                shape:wb.shape_keys=\"small\"):    \n",
    "    image=cv2.cvtColor(images[i],cv2.COLOR_BGR2RGB)\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    wb = WindowBoxes(height, width)\n",
    "    box_color=wb.box_colour_dict\n",
    "\n",
    "    window_dict = wb.build_window_boxes(height, width, all_shapes, shape) \n",
    "    window_img=np.copy(image)\n",
    "    for size, windows in window_dict.items():\n",
    "        window_img = draw_boxes(window_img, windows, color=box_color[size], thick=2)   \n",
    "    \n",
    "    return arr2img(window_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise an object to contain common parameters\n",
    "color_space = 'YCrCb' # Can be BGR, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 32  # HOG orientations\n",
    "pix_per_cell = 16 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (32, 32) # Spatial binning dimensions\n",
    "hist_bins = 32    # Number of histogram bins\n",
    "hist_range = (0,256)\n",
    "spatial_feat = False # Spatial features on or off\n",
    "hist_feat = False # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "\n",
    "    \n",
    "search_params = SearchParams(color_space, orient, pix_per_cell, cell_per_block, hog_channel, spatial_size,\n",
    "                  hist_bins, hist_range, spatial_feat, hist_feat, hog_feat, svc, X_scaler)\n",
    "print(search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def camera_window_box_test(images=fixed(pimages), i:(0,len(pimages)-1)=0, shape:wb.shape_keys=\"small\"):\n",
    "    camera_image=CameraImage(images[i])\n",
    "    window_boxes=WindowBoxes(camera_image.height, camera_image.width)               \n",
    "\n",
    "    img=CameraImage.slice_bounding_box_shape_resize_64x64(camera_image.image, window_boxes, shape)\n",
    "    #print(window_boxes.bounding_box(shape), window_boxes.resize_64x64_ratio(shape), img.shape)\n",
    "    return arr2img(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def hog_slice_test(images=fixed(vimages), i:(0,len(vimages)-1)=0,\n",
    "                   shape:wb.shape_keys=\"small\"):\n",
    "    camera_image = CameraImage(images[i])\n",
    "    window_boxes = WindowBoxes(camera_image.height, camera_image.width)\n",
    "    image_slice = ImageSlice(camera_image, window_boxes, search_params, shape)\n",
    "    image_windows = [wbs for wbs in image_slice.window_generator()]\n",
    "    image = image_slice.image\n",
    "\n",
    "    hog_image = image_slice.hog_image(1)\n",
    "#     print(window_boxes.bounding_box(shape), window_boxes.resize_64x64_ratio(shape), image.shape)\n",
    "  \n",
    "    hog_features_list = image_slice.hog_features_list\n",
    "#     print(len(hog_features_list))\n",
    "#     print(\"hog_features_list[0].values.shape=\",hog_features_list[0].values.shape)\n",
    "#     print(image_slice.image.shape,hog_image.shape)\n",
    "    #print(window_boxes.windows(shape))\n",
    "#     print(image_windows)\n",
    "\n",
    "#     for w in image_windows:\n",
    "#         print(\"windows: %r slice_window %r hog: %r\" % (w.bbox, w.bbox_slice,\n",
    "#                                                        image_slice.window_hog_features(w.bbox_slice)))\n",
    "    fig = plt.figure(figsize=(20,8))\n",
    "    plt.subplot(311)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)[:,:,2], cmap='gray')\n",
    "    plt.title('Original Image Slice')\n",
    "    plt.subplot(312)\n",
    "    plt.imshow(hog_image, cmap='gray')\n",
    "    plt.title('HOG Image Slice')\n",
    "#     plt.subplot(313)\n",
    "#     plt.imshow(hog_image, cmap='gray')\n",
    "#     plt.title('RHS Slice')\n",
    "#     plt.imshow(cv2.cvtColor(image_slice.slice_window(image_windows[-1:][0].bbox_slice), cv2.COLOR_YCrCb2RGB))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from scipy import ndimage\n",
    "\n",
    "loop = asyncio.new_event_loop()\n",
    "asyncio.set_event_loop(loop)\n",
    "\n",
    "vehicle_detection = VehicleDetection(search_params,timages[0].shape[0], timages[0].shape[1], loop)\n",
    "\n",
    "@interact\n",
    "def hot_windows_test(images=fixed(pimages), i:(0,len(pimages)-1)=0):\n",
    "\n",
    "#     vehicle_detection = VehicleDetection(search_params,images[i].shape[0], images[i].shape[1], loop)\n",
    "    vehicle_detection.image = images[i]\n",
    "    \n",
    "    heatmap = vehicle_detection.heatmap\n",
    "    heatmap_history = vehicle_detection.heatmap_history\n",
    "    labels=vehicle_detection.labels\n",
    "#     print(\"history count\", vehicle_detection.heatmap_history_count)\n",
    "    print(\"label car count\", labels[1], labels[0].shape, labels[0][0].shape)\n",
    "    print(\"box variance\", np.around(vehicle_detection.box_variance,decimals=3))\n",
    "    print(\"labelled boxes\", vehicle_detection.labelled_boxes)\n",
    "    print(\"planes\", vehicle_detection.label_box_planes)\n",
    "    \n",
    "    for car_number in range(1, labels[1] + 1):\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            #print(car_number)\n",
    "            nonzeroz = np.array(nonzero[0])\n",
    "            nonzeroy = np.array(nonzero[1])\n",
    "            nonzerox = np.array(nonzero[2])\n",
    "            #print(nonzeroy, nonzerox, nonzeroz)\n",
    "    \n",
    "\n",
    "    nplots=vehicle_detection.heatmap_history_count\n",
    "    fig = plt.figure(figsize=(15,vehicle_detection.heatmap_history_count*5))\n",
    "    \n",
    "    for i in range(0,vehicle_detection.heatmap_history_count):\n",
    "        plt.subplot(1, nplots, i+1)\n",
    "        \n",
    "        heatmap=heatmap_history[i]\n",
    "        plt.imshow(heatmap,cmap='inferno')\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "    fig.tight_layout()    \n",
    "    \n",
    "    \n",
    "#     fig = plt.figure(figsize=(12,10))\n",
    "#     plt.subplot(131)\n",
    "    \n",
    "#     print(labels[1], 'cars found')\n",
    "#     plt.imshow(labels[0][0], cmap='gray')\n",
    "#     plt.subplot(132)\n",
    "#     plt.imshow(heatmap)\n",
    "    \n",
    "#     f, ax = plt.subplots(133,figsize=(6, 6))\n",
    "#     nonzero = (labels[0] > 0).nonzero()\n",
    "#     nonzeroz = np.array(nonzero[0])\n",
    "#     nonzeroy = np.array(nonzero[1])\n",
    "#     nonzerox = np.array(nonzero[2])\n",
    "  \n",
    "#     ax = Axes3D(f)\n",
    "#     ax.scatter(nonzerox,nonzeroy,nonzeroz)\n",
    "    #return arr2img(labels[0])\n",
    "    \n",
    "#     return arr2img(vehicle_detection.heatmap_decorated)\n",
    "    return arr2img(cv2.cvtColor(cv2.resize(vehicle_detection.result,None,fx=.5,fy=.5),cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2img(vehicle_detection.heatmap_decorated)\n",
    "#vehicle_detection.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = asyncio.new_event_loop()\n",
    "asyncio.set_event_loop(loop)\n",
    "\n",
    "rimages=[]\n",
    "def do_project_video(file_name, output_name):\n",
    "    height, width = (720,1280)\n",
    "    \n",
    "    count=0\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    detection = VehicleDetection(search_params, height, width, loop)\n",
    "    \n",
    "    def process_image(image):\n",
    "        nonlocal count\n",
    "        \n",
    "        # process the lane image\n",
    "        detection.image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        result = cv2.cvtColor(detection.result, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        result = cv2.putText(result,'%4d' % count,(5,700), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        count +=1\n",
    "        \n",
    "        rimages.append(result)\n",
    "        return result\n",
    "\n",
    "    clip1 = VideoFileClip(file_name)\n",
    "    lane_clip = clip1.fl_image(process_image) \n",
    "    %time lane_clip.write_videofile(output_name, audio=False)\n",
    "    \n",
    "    return lane_clip\n",
    "\n",
    "# detection_clip = do_project_video(\"test_video.mp4\",\"test_video_detection.mp4\")\n",
    "detection_clip = do_project_video(\"project_video.mp4\",\"project_video_detection.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"test_video_detection.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def result_images_test(images=fixed(rimages), i:(0,len(rimages)-1)=0):\n",
    "    return arr2img(rimages[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
